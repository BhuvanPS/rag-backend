# RAG Chatbot Backend

This directory contains the Python backend for the Portfolio Chatbot. It uses **Flask** to serve the API and **Google Gemini (via `google-generativeai`)** for the chatbot logic and RAG (Retrieval-Augmented Generation).

## ğŸ“‚ File Structure

*   **`app.py`**: The Flask server entry point. Defines the `/api/chat` endpoint.
*   **`chatbot.py`**: Contains the `PortfolioChatbot` class, which handles:
    *   Loading embeddings from `embeddings.json`.
    *   Finding relevant context using Cosine Similarity.
    *   Generating responses using the Gemini API.
*   **`generate_embeddings.py`**: A script to extract data from `../Portfolio/data.js` and generate vector embeddings.
*   **`embeddings.json`**: The database of vector embeddings (generated by the script).
*   **`requirements.txt`**: Python dependencies.

## ğŸš€ Local Setup

1.  **Navigate to the backend directory:**
    ```bash
    cd rag-backend
    ```

2.  **Install Dependencies:**
    ```bash
    pip install -r requirements.txt
    ```

3.  **Environment Variables:**
    Ensure you have a `.env` file in the root `Portfolio` directory (or inside `rag-backend`) with your API key:
    ```env
    GEMINI_API_KEY=your_api_key_here
    ```

4.  **Run the Server:**
    ```bash
    python app.py
    ```
    The server will start at `http://localhost:5001`.

## ğŸ”„ Regenerating Embeddings

If you update your portfolio data in `data.js`, you need to regenerate the embeddings:

```bash
python generate_embeddings.py
```
This will update `embeddings.json`.

## â˜ï¸ Deployment (Render)

This backend is ready to be deployed on [Render](https://render.com/).

*   **Root Directory**: `rag-backend`
*   **Runtime**: Python 3
*   **Build Command**: `pip install -r requirements.txt`
*   **Start Command**: `gunicorn app:app`
*   **Environment Variables**: Add `GEMINI_API_KEY` and `PYTHON_VERSION` (e.g., `3.10.0`).
